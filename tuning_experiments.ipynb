{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45e2dd6-e02e-4117-963c-a6e4df39352b",
   "metadata": {},
   "source": [
    "# Tuning experiments for the Movielens dataset\n",
    "\n",
    "Feel free to re-run this and change hyperparameters as you see fit.\n",
    "\n",
    "This notebook should also be a good place to load the data only once and then train multiple times, generate charts, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1dc3c1-c8d8-4e91-bbc3-bf22424ab31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_data, train_test_split, MovielensDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import argparse\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from gmf import GMF\n",
    "from ncf_mlp import NCF_MLP\n",
    "from neural_mf import NEURAL_MF\n",
    "\n",
    "from train import train_gmf, train_joint_nerual_mf, train_mlp, train_neural_mf, train_loop, test_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb785f3c-40a4-44ef-8e17-99a64cf0bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting hyperparameters\n",
    "learning_rate = 0.05\n",
    "weight_decay = 0.0000001\n",
    "epochs = 5\n",
    "batch_size = 1024\n",
    "latent_dims = 16\n",
    "alpha: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e5df12f-f52c-4d67-b87c-fad5bccdbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ce424df-270a-438a-a667-6100406c869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "dataset = '100k'\n",
    "data, num_users, num_items = load_data(dataset)\n",
    "train, test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4709cca1-1aee-4846-9f2e-4e0778e15cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MovielensDataset(users=train['user_id'], movies=train['movie_id'], ratings = train['rating'])\n",
    "test = MovielensDataset(users=test['user_id'], movies=test['movie_id'], ratings = test['rating'])\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True, num_workers= 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7dd4c7-857a-42fb-89f0-69611ed4292b",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2007a37-f6c6-4ed4-b09a-11a45ada42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune some hyperparameters for GMF\n",
    "def tune_lr(model_type='gmf'):\n",
    "    learning_rates = np.array([0.001, 0.01, 0.05, 0.07, 0.1, 0.2])\n",
    "    rmse_history = []\n",
    "    best_model = None\n",
    "    best_lr = 0.01\n",
    "    best_RMSE = np.inf\n",
    "    for lr in learning_rates:\n",
    "        if model_type == 'gmf':\n",
    "            print('TRAINING GMF')\n",
    "            train_model = train_gmf\n",
    "        elif model_type == 'mlp':\n",
    "            print('TRAINING MLP')\n",
    "            train_model = train_mlp\n",
    "        else:\n",
    "            print('TRAINING NMF')\n",
    "            train_model = train_nmf\n",
    "        model = train_model(train_dataloader, test_dataloader, num_users, num_items, epochs, latent_dims,\n",
    "                            lr, # Param being tuned\n",
    "                            'adam', criterion=nn.CrossEntropyLoss(), device=device, weight_decay=weight_decay)\n",
    "\n",
    "        # Select the best model based on TRAIN RMSE, not TEST RMSE\n",
    "        rmse = test_loop(train_dataloader, model, nn.CrossEntropyLoss(), device)\n",
    "        rmse_history.append(rmse)\n",
    "\n",
    "        if rmse < best_RMSE:\n",
    "            best_lr = lr\n",
    "            best_RMSE = rmse\n",
    "            best_model = model\n",
    "\n",
    "    rmse_history = np.array(rmse_history)\n",
    "\n",
    "    print()\n",
    "    print('Finished tuning model', model_type)\n",
    "    print('Best Learning Rate:', best_lr)\n",
    "    print('Best RMSE:', best_RMSE)\n",
    "\n",
    "    return (learning_rates, rmse_history, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b673bd21-50b7-4526-8327-2206ec041712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 4924.128418  [ 1024/79619]\n",
      "Test MSE 0.08242572277956661\n",
      "Test RMSE 0.2870988031663779\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 5020.475098  [ 1024/79619]\n",
      "Test MSE 0.0736839597842501\n",
      "Test RMSE 0.27144789515531353\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 5034.125977  [ 1024/79619]\n",
      "Test MSE 0.07028287796379766\n",
      "Test RMSE 0.26510918121369853\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 4990.594238  [ 1024/79619]\n",
      "Test MSE 0.06921984075217374\n",
      "Test RMSE 0.26309663766793706\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 5015.585938  [ 1024/79619]\n",
      "Test MSE 0.06892058711736244\n",
      "Test RMSE 0.262527307374609\n",
      "Test MSE 0.06801088713490124\n",
      "Test RMSE 0.26078897050086536\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 5114.275391  [ 1024/79619]\n",
      "Test MSE 0.1278021387128007\n",
      "Test RMSE 0.3574942499017302\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 5040.489258  [ 1024/79619]\n",
      "Test MSE 0.163598129205617\n",
      "Test RMSE 0.40447265569580476\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 5011.608398  [ 1024/79619]\n",
      "Test MSE 0.2329429545458749\n",
      "Test RMSE 0.4826416419517434\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 4973.623047  [ 1024/79619]\n",
      "Test MSE 0.2725940133039506\n",
      "Test RMSE 0.5221053660938093\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 5046.370117  [ 1024/79619]\n",
      "Test MSE 0.23470696527745555\n",
      "Test RMSE 0.48446564922340524\n",
      "Test MSE 0.22861196489975408\n",
      "Test RMSE 0.4781338357612375\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 5030.121094  [ 1024/79619]\n",
      "Test MSE 0.10514238260643766\n",
      "Test RMSE 0.32425666162229827\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4998.694336  [ 1024/79619]\n",
      "Test MSE 0.10332805021762259\n",
      "Test RMSE 0.3214468077577107\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 4998.749023  [ 1024/79619]\n",
      "Test MSE 0.08219303734284111\n",
      "Test RMSE 0.28669328095168384\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 5071.250488  [ 1024/79619]\n",
      "Test MSE 0.07247256694555819\n",
      "Test RMSE 0.2692072936336573\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 5075.904297  [ 1024/79619]\n",
      "Test MSE 0.0730497225656996\n",
      "Test RMSE 0.2702771217948341\n",
      "Test MSE 0.04248491820869461\n",
      "Test RMSE 0.2061186993183651\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 4992.212402  [ 1024/79619]\n",
      "Test MSE 0.491008313101369\n",
      "Test RMSE 0.7007198535087821\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4944.937500  [ 1024/79619]\n",
      "Test MSE 0.4702692790343819\n",
      "Test RMSE 0.6857618238385554\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 5030.260742  [ 1024/79619]\n",
      "Test MSE 0.07374437945630503\n",
      "Test RMSE 0.27155916382310696\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 4929.421875  [ 1024/79619]\n",
      "Test MSE 0.05315031014210757\n",
      "Test RMSE 0.23054351030143436\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 4993.733887  [ 1024/79619]\n",
      "Test MSE 0.05634215832341997\n",
      "Test RMSE 0.23736503180422336\n",
      "Test MSE 0.030921432375347058\n",
      "Test RMSE 0.17584491000693497\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 5021.878906  [ 1024/79619]\n",
      "Test MSE 0.12662196841728265\n",
      "Test RMSE 0.3558398072409587\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4948.888184  [ 1024/79619]\n",
      "Test MSE 0.11873654717233453\n",
      "Test RMSE 0.3445816988354642\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 4977.636230  [ 1024/79619]\n",
      "Test MSE 0.11053043742587962\n",
      "Test RMSE 0.3324611818331271\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 4954.519531  [ 1024/79619]\n",
      "Test MSE 0.09761467696895446\n",
      "Test RMSE 0.31243347606963384\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 4999.852539  [ 1024/79619]\n",
      "Test MSE 0.10212283616236625\n",
      "Test RMSE 0.319566638062183\n",
      "Test MSE 0.07847619436157416\n",
      "Test RMSE 0.28013602831762674\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 5019.506836  [ 1024/79619]\n",
      "Test MSE 0.5391224624361566\n",
      "Test RMSE 0.7342495913762271\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 5061.244141  [ 1024/79619]\n",
      "Test MSE 0.5466380110182968\n",
      "Test RMSE 0.7393497217273411\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 4979.507812  [ 1024/79619]\n",
      "Test MSE 0.5455777394607311\n",
      "Test RMSE 0.7386323439037388\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 5044.928711  [ 1024/79619]\n",
      "Test MSE 0.5479627544711461\n",
      "Test RMSE 0.7402450637938399\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 5156.959473  [ 1024/79619]\n",
      "Test MSE 0.5475493050933125\n",
      "Test RMSE 0.7399657458918706\n",
      "Test MSE 0.5479617614224468\n",
      "Test RMSE 0.7402443930368178\n",
      "\n",
      "Finished tuning model gmf\n",
      "Best Learning Rate: 0.07\n",
      "Best RMSE: 0.17584491000693497\n",
      "[0.001 0.01  0.05  0.07  0.1   0.2  ]\n",
      "[0.26078897 0.47813384 0.2061187  0.17584491 0.28013603 0.74024439]\n"
     ]
    }
   ],
   "source": [
    "gmf_lr, gmf_rmse, opt_model = tune_lr('gmf')\n",
    "# TODO: Plot this\n",
    "print(gmf_lr)\n",
    "print(gmf_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fd4ed52-ae40-47e9-9ee6-ff61c7db424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune some hyperparameters for GMF\n",
    "def tune_dims(model_type='gmf'):\n",
    "    dims = [8, 16, 32, 64, 128, 256]\n",
    "    rmse_history = []\n",
    "    best_model = None\n",
    "    best_dim = 0.01\n",
    "    best_RMSE = np.inf\n",
    "    for dim in dims:\n",
    "        if model_type == 'gmf':\n",
    "            print('TRAINING GMF')\n",
    "            train_model = train_gmf\n",
    "        elif model_type == 'mlp':\n",
    "            print('TRAINING MLP')\n",
    "            train_model = train_mlp\n",
    "        else:\n",
    "            print('TRAINING NMF')\n",
    "            train_model = train_nmf\n",
    "        model = train_model(train_dataloader, test_dataloader, num_users, num_items, epochs,\n",
    "                            dim, # Param being tuned \n",
    "                            learning_rate, 'adam', criterion=nn.CrossEntropyLoss(), device=device, weight_decay=weight_decay)\n",
    "\n",
    "        # Select the best model based on TRAIN RMSE, not TEST RMSE\n",
    "        rmse = test_loop(train_dataloader, model, nn.CrossEntropyLoss(), device)\n",
    "        rmse_history.append(rmse)\n",
    "\n",
    "        if rmse < best_RMSE:\n",
    "            best_dim = dim\n",
    "            best_RMSE = rmse\n",
    "            best_model = model\n",
    "\n",
    "    rmse_history = np.array(rmse_history)\n",
    "\n",
    "    print()\n",
    "    print('Finished tuning model', model_type)\n",
    "    print('Best Embedding Dim:', best_dim)\n",
    "    print('Best RMSE:', best_RMSE)\n",
    "\n",
    "    return (dims, rmse_history, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c58e328d-9ba1-4fe8-ae02-febd490cb0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 5021.759766  [ 1024/79619]\n",
      "Test MSE 0.4614989715264173\n",
      "Test RMSE 0.6793371560031273\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4994.810547  [ 1024/79619]\n",
      "Test MSE 0.4836110871890738\n",
      "Test RMSE 0.6954215176345019\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 5070.592773  [ 1024/79619]\n",
      "Test MSE 0.2567314553289608\n",
      "Test RMSE 0.5066867427996916\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 5000.495117  [ 1024/79619]\n",
      "Test MSE 0.04493780511762326\n",
      "Test RMSE 0.21198538892485788\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 5058.890625  [ 1024/79619]\n",
      "Test MSE 0.044639099556100105\n",
      "Test RMSE 0.21127967142179133\n",
      "Test MSE 0.030248094296741072\n",
      "Test RMSE 0.1739197927112986\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 5071.441895  [ 1024/79619]\n",
      "Test MSE 0.4418403193317014\n",
      "Test RMSE 0.6647107034881427\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4963.020508  [ 1024/79619]\n",
      "Test MSE 0.44970225380123363\n",
      "Test RMSE 0.670598429614351\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 5016.378418  [ 1024/79619]\n",
      "Test MSE 0.06433104509336492\n",
      "Test RMSE 0.2536356542234646\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 5035.652344  [ 1024/79619]\n",
      "Test MSE 0.049991743891307415\n",
      "Test RMSE 0.2235883357675606\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 4925.847656  [ 1024/79619]\n",
      "Test MSE 0.05240054730306483\n",
      "Test RMSE 0.22891165829434032\n",
      "Test MSE 0.028700288685883507\n",
      "Test RMSE 0.16941159548827675\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 4953.901367  [ 1024/79619]\n",
      "Test MSE 0.10705800402166159\n",
      "Test RMSE 0.32719719439760114\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4935.404297  [ 1024/79619]\n",
      "Test MSE 0.1120746393122532\n",
      "Test RMSE 0.3347755058427262\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 4954.885742  [ 1024/79619]\n",
      "Test MSE 0.08317755582020595\n",
      "Test RMSE 0.2884051938162798\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 4943.957031  [ 1024/79619]\n",
      "Test MSE 0.07543639863263325\n",
      "Test RMSE 0.27465687435895947\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 4874.413574  [ 1024/79619]\n",
      "Test MSE 0.07742703306233224\n",
      "Test RMSE 0.27825713479142317\n",
      "Test MSE 0.036454452456755625\n",
      "Test RMSE 0.1909304911656481\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 4998.897461  [ 1024/79619]\n",
      "Test MSE 0.11216525699267894\n",
      "Test RMSE 0.3349108194619561\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 5012.633301  [ 1024/79619]\n",
      "Test MSE 0.09996671136092078\n",
      "Test RMSE 0.31617512767597766\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 5054.261719  [ 1024/79619]\n",
      "Test MSE 0.08109913567126444\n",
      "Test RMSE 0.2847790997795738\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 4905.576172  [ 1024/79619]\n",
      "Test MSE 0.0769523269734131\n",
      "Test RMSE 0.27740282437894015\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 4940.321777  [ 1024/79619]\n",
      "Test MSE 0.07799165838127853\n",
      "Test RMSE 0.2792698665829855\n",
      "Test MSE 0.03183689118030065\n",
      "Test RMSE 0.17842895275235085\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 5020.680664  [ 1024/79619]\n",
      "Test MSE 0.11359071872566665\n",
      "Test RMSE 0.33703222208813605\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4952.893555  [ 1024/79619]\n",
      "Test MSE 0.10776783650751587\n",
      "Test RMSE 0.3282801189647583\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 4943.927734  [ 1024/79619]\n",
      "Test MSE 0.0929315038581546\n",
      "Test RMSE 0.30484668910479346\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 4939.193359  [ 1024/79619]\n",
      "Test MSE 0.08778654570390104\n",
      "Test RMSE 0.2962879439057571\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 5038.452148  [ 1024/79619]\n",
      "Test MSE 0.08075586640678256\n",
      "Test RMSE 0.2841757667479452\n",
      "Test MSE 0.03633749057822538\n",
      "Test RMSE 0.19062395069409663\n",
      "TRAINING GMF\n",
      "Epoch 1\n",
      "------------------------\n",
      "loss: 4929.197266  [ 1024/79619]\n",
      "Test MSE 0.1138763311935863\n",
      "Test RMSE 0.3374556729314034\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 4887.293945  [ 1024/79619]\n",
      "Test MSE 0.11083607012059005\n",
      "Test RMSE 0.33292051622059887\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 4959.851562  [ 1024/79619]\n",
      "Test MSE 0.10545741336506526\n",
      "Test RMSE 0.3247420720588345\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 5027.766602  [ 1024/79619]\n",
      "Test MSE 0.1005450771170669\n",
      "Test RMSE 0.31708843737523273\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 5000.628418  [ 1024/79619]\n",
      "Test MSE 0.09605148828400141\n",
      "Test RMSE 0.309921745419713\n",
      "Test MSE 0.053315092641373706\n",
      "Test RMSE 0.2309006120420076\n",
      "\n",
      "Finished tuning model gmf\n",
      "Best Embedding Dim: 16\n",
      "Best RMSE: 0.16941159548827675\n",
      "[8, 16, 32, 64, 128, 256]\n",
      "[0.17391979 0.1694116  0.19093049 0.17842895 0.19062395 0.23090061]\n"
     ]
    }
   ],
   "source": [
    "gmf_dim, gmf_rmse, opt_model = tune_dims('gmf')\n",
    "# TODO: Plot this\n",
    "print(gmf_dim)\n",
    "print(gmf_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf57ec-f2a4-4f88-9fe7-b22395b23b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
